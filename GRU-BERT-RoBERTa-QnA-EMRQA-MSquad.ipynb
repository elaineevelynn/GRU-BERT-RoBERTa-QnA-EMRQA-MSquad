{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "37d62dc5",
      "metadata": {},
      "source": [
        "# Proyek UAS NLP \n",
        "### Anggota Kelompok:\n",
        "* Christopher Nathaniel Tanamas // 222200153\n",
        "* Elaine Evelyn // 222102311\n",
        "* Grace Calista Lim // 222102176"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b32a3b03",
      "metadata": {},
      "source": [
        "# Masalah\n",
        "Dokter seringkali membutuhkan akses cepat dan tepat terhadap informasi yang relevan dalam rekam medis pasien untuk menjawab pertanyaan medis yang muncul selama konsultasi. Namun, menelusuri catatan medis secara manual bisa memakan waktu dan tidak efisien. Oleh karena itu, kami menawarkan solusi berupa model NLP Question Answering yang dapat membantu dokter menjawab pertanyaan berbasis teks secara akurat dan relevan, dengan memanfaatkan konteks dari rekam medis pasien yang sudah tersedia.\n",
        "\n",
        "Model Question Answering ini dirancang untuk memberikan jawaban atas pertanyaan medis berdasarkan informasi dalam rekam medis pasien, seperti riwayat konsumsi obat, diagnosis sebelumnya, hingga prosedur medis yang telah dijalani. Dalam proyek ini, kami menggunakan dataset EMRQA-MSquad yang berfokus pada pertanyaan-pertanyaan medis umum. Model yang akan kami eksplorasi meliputi GRU, BERT, dan RoBERTa."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "632742b9",
      "metadata": {
        "id": "632742b9"
      },
      "source": [
        "# Import All Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "8fdd2b6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fdd2b6b",
        "outputId": "4105fa88-67f1-4c8f-fbc2-ed6f3f6c0ab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1b95804",
      "metadata": {
        "id": "f1b95804"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import (AutoTokenizer, AutoModelForQuestionAnswering, default_data_collator, TrainingArguments, Trainer, pipeline)\n",
        "from evaluate import load\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edfb938a",
      "metadata": {},
      "source": [
        "# Pilihan Penggunaan GPU jika Tersedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff955f02",
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af1ba400",
      "metadata": {
        "id": "af1ba400"
      },
      "source": [
        "# Load Dataset\n",
        "Kami menggunakan dataset EMRQA-MSquad yang tersedia di Hugging Face. Dataset ini berisi kumpulan pertanyaan dan jawaban yang berfokus pada topik-topik medis. Data ini mengandung pertanyaan medis yang sering diajukan oleh pasien atau tenaga medis, bersama dengan jawaban yang relevan. Dataset ini sangat cocok untuk digunakan dalam pelatihan model QnA medis, karena mencakup berbagai pertanyaan yang berfokus pada penyakit, gejala, prosedur medis, dan pengobatan. Dataset ini dapat diakses melalui https://huggingface.co/datasets/Eladio/emrqa-msquad/viewer/default/train?p=2&views%5B%5D=train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0d536ce9",
      "metadata": {
        "id": "0d536ce9"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"Eladio/emrqa-msquad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "19387ea8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19387ea8",
        "outputId": "be9e02a8-0071-4884-bd10-f5578333b9f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['context', 'question', 'answers'],\n",
              "        num_rows: 130956\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['context', 'question', 'answers'],\n",
              "        num_rows: 32739\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afb4e4f2",
      "metadata": {
        "id": "afb4e4f2"
      },
      "source": [
        "## Train test split\n",
        "Train test split dilakukan dengan menggunakan dataset yang telah disediakan. Dataset berisikan train data dan validation data. Maka, kami menggunakan train data untuk training dan validation data untuk testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "3b67607d",
      "metadata": {
        "id": "3b67607d"
      },
      "outputs": [],
      "source": [
        "raw_train_dataset = dataset[\"train\"]\n",
        "raw_test_dataset = dataset[\"validation\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c88e398d",
      "metadata": {
        "id": "c88e398d"
      },
      "source": [
        "Menggunakan sebagian dataset untuk training agar tidak terlalu memakan banyak waktu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "41a1c9b0",
      "metadata": {
        "id": "41a1c9b0"
      },
      "outputs": [],
      "source": [
        "selected_train = raw_train_dataset.select(range(5000)) # gunakan 5000 data\n",
        "selected_test = raw_test_dataset.select(range(1000)) # gunakan 1000 data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bcd0ef4",
      "metadata": {
        "id": "7bcd0ef4"
      },
      "source": [
        "Kami menambahkan ID pada setiap data untuk memudahkan proses evaluasi model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "d2696cc1",
      "metadata": {
        "id": "d2696cc1"
      },
      "outputs": [],
      "source": [
        "def add_id(example, idx):\n",
        "    example[\"id\"] = str(idx)\n",
        "    return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b5ef2d14",
      "metadata": {
        "id": "b5ef2d14"
      },
      "outputs": [],
      "source": [
        "train_dataset = selected_train.map(add_id, with_indices=True)\n",
        "test_dataset = selected_test.map(add_id, with_indices=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75cd66a3",
      "metadata": {
        "id": "75cd66a3"
      },
      "source": [
        "# Pre-Processing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04d44139",
      "metadata": {
        "id": "04d44139"
      },
      "source": [
        "### Siapkan tokenizer untuk setiap model\n",
        "**NOTE**: bert_tokenizer akan digunakan juga sebagai tokenizer data GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "26f98298",
      "metadata": {
        "id": "26f98298"
      },
      "outputs": [],
      "source": [
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "57da8a9e",
      "metadata": {
        "id": "57da8a9e"
      },
      "outputs": [],
      "source": [
        "roberta_tokenizer = AutoTokenizer.from_pretrained(\"deepset/tinyroberta-squad2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89fc4119",
      "metadata": {
        "id": "89fc4119"
      },
      "source": [
        "### Fungsi Pre-processing\n",
        "\n",
        "Pre-processing digunakan untuk tokenisasi data, padding, dan mencari posisi jawaban setelah ditokenisasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa038dc",
      "metadata": {
        "id": "cfa038dc"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples, model_name):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "\n",
        "    # Tentukan jenis model yang digunakan\n",
        "    if model_name == \"bert\" or model_name==\"gru\":\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    elif model_name == \"roberta\":\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"deepset/tinyroberta-squad2\")\n",
        "\n",
        "    # Tokenisasi\n",
        "    tokenized = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        truncation=\"only_second\", # potong bagian konteks jika panjang melebihi batas\n",
        "        max_length=384, # batas token adalah 384\n",
        "        stride=128, # jarak geser sliding window\n",
        "        return_overflowing_tokens=True, # kembalikan contoh yang terpotong (jika ada)\n",
        "        return_offsets_mapping=True, # offset (indeks awal dan akhir karakter)\n",
        "        padding=\"max_length\" # padding agar panjang token sama\n",
        "    )\n",
        "\n",
        "    sample_mapping = tokenized.pop(\"overflow_to_sample_mapping\") # menghubungkan token yang terpotong dengan contoh asli\n",
        "    offset_mapping = tokenized[\"offset_mapping\"] # untuk menemukan jawaban dalam konteks\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    ids = []\n",
        "\n",
        "    # mencari posisi jawaban untuk setiap contoh\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        input_ids = tokenized[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id) # posisi awal\n",
        "        sequence_ids = tokenized.sequence_ids(i) # apakah token dari pertanyaan atau konteks\n",
        "\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "        ids.append(examples[\"id\"][sample_index])\n",
        "\n",
        "        # Jika tidak ada jawaban\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            start_positions.append(cls_index)\n",
        "            end_positions.append(cls_index)\n",
        "        # kondisi ketika ada jawaban\n",
        "        else:\n",
        "            # menemukan posisi token untuk jawaban\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != 1:\n",
        "                token_start_index += 1\n",
        "\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != 1:\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # menentukan token awal dan akhir jawaban\n",
        "            if offsets[token_start_index][0] > start_char or offsets[token_end_index][1] < end_char:\n",
        "                start_positions.append(cls_index)\n",
        "                end_positions.append(cls_index)\n",
        "            else:\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                start_positions.append(token_start_index - 1)\n",
        "\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                end_positions.append(token_end_index + 1)\n",
        "\n",
        "    tokenized[\"start_positions\"] = start_positions\n",
        "    tokenized[\"end_positions\"] = end_positions\n",
        "    tokenized[\"id\"] = ids\n",
        "    return tokenized\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b3361ae",
      "metadata": {},
      "source": [
        "### Pre-processing For GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5962603d",
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_train_gru = train_dataset.map(\n",
        "    lambda examples: preprocess_function(examples, model_name=\"gru\"),\n",
        "    batched=True,\n",
        "    remove_columns=train_dataset.column_names)\n",
        "tokenized_test_gru = test_dataset.map(\n",
        "    lambda examples: preprocess_function(examples, model_name=\"gru\"),\n",
        "    batched=True,\n",
        "    remove_columns=test_dataset.column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d87c3dba",
      "metadata": {
        "id": "d87c3dba"
      },
      "source": [
        "### Pre-processing For Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "00c396cd",
      "metadata": {
        "id": "00c396cd"
      },
      "outputs": [],
      "source": [
        "tokenized_train_bert = train_dataset.map(\n",
        "    lambda examples: preprocess_function(examples, model_name=\"bert\"),\n",
        "    batched=True,\n",
        "    remove_columns=train_dataset.column_names)\n",
        "tokenized_test_bert = test_dataset.map(\n",
        "    lambda examples: preprocess_function(examples, model_name=\"bert\"),\n",
        "    batched=True,\n",
        "    remove_columns=test_dataset.column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4288b17",
      "metadata": {
        "id": "f4288b17"
      },
      "source": [
        "### Pre-processing For Roberta Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "af8276f9",
      "metadata": {
        "id": "af8276f9"
      },
      "outputs": [],
      "source": [
        "tokenized_train_roberta = train_dataset.map(\n",
        "    lambda examples: preprocess_function(examples, model_name=\"roberta\"),\n",
        "    batched=True,\n",
        "    remove_columns=train_dataset.column_names)\n",
        "tokenized_test_roberta = test_dataset.map(\n",
        "    lambda examples: preprocess_function(examples, model_name=\"roberta\"),\n",
        "    batched=True,\n",
        "    remove_columns=test_dataset.column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49d3559a",
      "metadata": {
        "id": "49d3559a"
      },
      "source": [
        "# Model Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d22bbe9",
      "metadata": {},
      "source": [
        "### GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c375208b",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GRUForQA(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256):\n",
        "        super(GRUForQA, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim) # Konversi token ID ke vektor\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=True) # bidirectional agar bisa memahami konteks sebelum dan sesudah\n",
        "        self.fc_start = nn.Linear(hidden_dim * 2, 1) # token awal\n",
        "        self.fc_end = nn.Linear(hidden_dim * 2, 1) # token akhir\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        embedded = self.embedding(input_ids)\n",
        "        gru_out, _ = self.gru(embedded) # vektor hasil embedding\n",
        "        start_logits = self.fc_start(gru_out).squeeze(-1) # output posisi awal\n",
        "        end_logits = self.fc_end(gru_out).squeeze(-1) # output posisi akhir\n",
        "        return start_logits, end_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc224e51",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Penggabungan data dari kumpulan batch. Ubah data menjadi bentuk tensor\n",
        "def collate_fn(batch):\n",
        "    input_ids = torch.tensor([item[\"input_ids\"] for item in batch]) \n",
        "    start_positions = torch.tensor([item[\"start_positions\"] for item in batch])\n",
        "    end_positions = torch.tensor([item[\"end_positions\"] for item in batch])\n",
        "    return input_ids, start_positions, end_positions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2547292",
      "metadata": {},
      "source": [
        "### Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e82a6e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e82a6e0",
        "outputId": "57e5d758-48d8-49a0-b2bf-13fc6492c416"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "bert_model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "173a119b",
      "metadata": {},
      "source": [
        "### Roberta Model\n",
        "Model diambil dari https://huggingface.co/deepset/tinyroberta-squad2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bc456a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "roberta_model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/tinyroberta-squad2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13d3740e",
      "metadata": {
        "id": "13d3740e"
      },
      "source": [
        "## Gunakan API untuk training model (kecuali GRU)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3d7fdd5",
      "metadata": {},
      "source": [
        "#### Training model untuk GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ae95dbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_gru_model(model, train_dataset, epochs=3, batch_size=16, lr=5e-4):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    loss_fn = CrossEntropyLoss()\n",
        "    dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn) # Ambil batch data\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        step = 0\n",
        "        for input_ids, start_pos, end_pos in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"): # loop untuk setiap batch\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Pakai GPU\n",
        "            input_ids = input_ids.to(device)\n",
        "            start_pos = start_pos.to(device)\n",
        "            end_pos = end_pos.to(device)\n",
        "\n",
        "            # Mendapatkan logits untuk start dan end dari model\n",
        "            start_logits, end_logits = model(input_ids)\n",
        "\n",
        "            # Menghitung loss untuk start dan end positions\n",
        "            loss_start = loss_fn(start_logits, start_pos)\n",
        "            loss_end = loss_fn(end_logits, end_pos)\n",
        "            loss = (loss_start + loss_end) / 2\n",
        "\n",
        "            # Backward untuk hitung gradien\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            step += 1\n",
        "            avg_loss = total_loss / step\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8e49216",
      "metadata": {},
      "source": [
        "### Training Arguments untuk Bert dan Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "c95b2903",
      "metadata": {
        "id": "c95b2903"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-qa-emrqa\",   # folder hasil model\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,  # regularisasi\n",
        "    logging_steps=200\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb0a936",
      "metadata": {
        "id": "4bb0a936"
      },
      "source": [
        "#### Training model untuk Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7526f759",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7526f759",
        "outputId": "b1f4ab0c-7847-4826-9852-c25b58cae07c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-32-1663f4ef2c6f>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  bert_trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "bert_trainer = Trainer(\n",
        "    model=bert_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_bert,\n",
        "    eval_dataset=tokenized_test_bert,\n",
        "    tokenizer=bert_tokenizer,\n",
        "    data_collator=default_data_collator, # mengatur penggabungan batch\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b1783eb",
      "metadata": {
        "id": "4b1783eb"
      },
      "source": [
        "#### Training model untuk Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "6ea76e32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ea76e32",
        "outputId": "9d1fd32d-066a-4d3b-857a-89954dfdd1fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-bf931493b694>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  roberta_trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "roberta_trainer = Trainer(\n",
        "    model=roberta_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_roberta,\n",
        "    eval_dataset=tokenized_test_roberta,\n",
        "    tokenizer=roberta_tokenizer,\n",
        "    data_collator=default_data_collator, # mengatur penggabungan batch\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1059b74",
      "metadata": {
        "id": "e1059b74"
      },
      "source": [
        "# Model Training\n",
        "Training model dan menyimpan modelnya"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8a1a042",
      "metadata": {},
      "source": [
        "#### Training model GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13761287",
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_size = bert_tokenizer.vocab_size # ambil ukuran kosakata\n",
        "gru_model = GRUForQA(vocab_size).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a637fa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "004a439cef3f481295e9f0dee2011ae0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1:   0%|          | 0/822 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Loss: 2.5197\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d56f9e3ef487494b88c08f9d65053daf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2:   0%|          | 0/822 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Loss: 2.1548\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f5ad398611546d4ad6fb245d04d3800",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3:   0%|          | 0/822 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 - Loss: 1.9749\n"
          ]
        }
      ],
      "source": [
        "train_gru_model(gru_model, tokenized_train_gru)\n",
        "gru_model.save_pretrained(\"./model_gru\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71056eb6",
      "metadata": {},
      "source": [
        "#### Training model Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7099f0ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "7099f0ab",
        "outputId": "82c8a963-a668-4d47-81ae-43aa88086ce9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2466' max='2466' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2466/2466 47:16, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.154700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.299200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.191500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.136600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.904600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.902900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.857400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.833400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.688500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.664300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.673500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.640700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bert_trainer.train()\n",
        "bert_model.save_pretrained(\"./model_bert\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02a6ce96",
      "metadata": {},
      "source": [
        "#### Training model Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e80c35f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "e80c35f1",
        "outputId": "0ed562ff-bedf-4d94-b4b2-421c104c16f5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2457' max='2457' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2457/2457 24:16, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.436200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.203400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.107400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.057800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.918700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.820400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.836800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.797000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.654100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.664100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.610500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.619300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "roberta_trainer.train()\n",
        "roberta_model.save_pretrained(\"./model_roberta\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9448a752",
      "metadata": {
        "id": "9448a752"
      },
      "source": [
        "# Evaluation\n",
        "Kami menggunakan 2 metriks untuk evaluasi, yaitu Exact Match (EM) dan F1 score. \n",
        "- **Exact Match (EM)** adalah seberapa sering prediksi model tepat sama dengan jawaban sebenarnya. \n",
        "- **F1 Score** mengukur kemiripan antara prediksi dan jawaban (berdasarkan precision dan recall)\n",
        "\n",
        "#### Exact Match (EM)\n",
        "\n",
        "$$\n",
        "\\text{EM} = \\frac{\\text{Jumlah prediksi tepat}}{\\text{Jumlah total pertanyaan}} \\times 100\\%\n",
        "$$\n",
        "\n",
        "#### F1 Score\n",
        "\n",
        "$$\n",
        "F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2a46d1a",
      "metadata": {
        "id": "b2a46d1a"
      },
      "source": [
        "#### Gunakan metriks squad untuk evaluasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "46bfd5d7",
      "metadata": {
        "id": "46bfd5d7"
      },
      "outputs": [],
      "source": [
        "metric = load(\"squad\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33596cd6",
      "metadata": {
        "id": "33596cd6"
      },
      "source": [
        "#### Post-processing digunakan untuk mengubah output dari model menjadi teks jawaban biasa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aae813ee",
      "metadata": {
        "id": "aae813ee"
      },
      "outputs": [],
      "source": [
        "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size=20, max_answer_length=30):\n",
        "    all_start_logits, all_end_logits = raw_predictions  # mengambil hasil prediksi model\n",
        "\n",
        "    # Hubungkan example dengan features\n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "    features_per_example = {}\n",
        "    for i, feature in enumerate(features):\n",
        "        example_id = feature[\"id\"]\n",
        "        features_per_example.setdefault(example_id, []).append(i)\n",
        "\n",
        "    predictions = {}\n",
        "\n",
        "    # ambil semua fitur untuk setiap example\n",
        "    for example_id, feature_indices in tqdm(features_per_example.items()):\n",
        "        context = examples[example_id_to_index[example_id]][\"context\"]\n",
        "\n",
        "        valid_answers = []\n",
        "\n",
        "        for feature_index in feature_indices:\n",
        "            start_logits = all_start_logits[feature_index]\n",
        "            end_logits = all_end_logits[feature_index]\n",
        "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            # mengambil kandidat jawaban\n",
        "            start_indexes = np.argsort(start_logits)[-1: -n_best_size - 1: -1].tolist()\n",
        "            end_indexes = np.argsort(end_logits)[-1: -n_best_size - 1: -1].tolist()\n",
        "\n",
        "            # periksa kombinasi kandidat token\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    if start_index >= len(offset_mapping) or end_index >= len(offset_mapping):\n",
        "                        continue\n",
        "                    if offset_mapping[start_index] is None or offset_mapping[end_index] is None:\n",
        "                        continue\n",
        "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                        continue\n",
        "\n",
        "                    # simpah skor jika valid\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    answer = context[start_char: end_char]\n",
        "                    score = start_logits[start_index] + end_logits[end_index]\n",
        "                    valid_answers.append({\"text\": answer, \"score\": score})\n",
        "\n",
        "        # pilih jawaban terbaik\n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
        "\n",
        "        # simpan hasil akhir\n",
        "        predictions[example_id] = best_answer[\"text\"]\n",
        "\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05fc4065",
      "metadata": {},
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "195dd3a4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "519d6596284e457e97a41c9d8c158165",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hasil evaluasi GRU:\n",
            "{'exact_match': 1.9, 'f1': 3.532710927370739}\n"
          ]
        }
      ],
      "source": [
        "dataloader = DataLoader(tokenized_test_gru, batch_size=16, collate_fn=collate_fn) # Membuat dataloader agar dapat diproses dalam batch\n",
        "all_start_logits, all_end_logits = [], []\n",
        "\n",
        "# mode evaluasi\n",
        "gru_model.eval()\n",
        "with torch.no_grad():\n",
        "    for input_ids, _, _ in dataloader:\n",
        "        input_ids = input_ids.to(device)\n",
        "        start_logits, end_logits = gru_model(input_ids) \n",
        "        all_start_logits.extend(start_logits.tolist()) # tambahin elemen ke list\n",
        "        all_end_logits.extend(end_logits.tolist())\n",
        "\n",
        "# Post-process predictions\n",
        "final_predictions = postprocess_qa_predictions(\n",
        "    examples=test_dataset,              # dataset asli\n",
        "    features=tokenized_test_gru,        # hasil tokenisasi\n",
        "    raw_predictions=(all_start_logits, all_end_logits)\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
        "references = [{\"id\": ex[\"id\"], \"answers\": {'answer_start': ex['answers']['answer_start'], 'text': ex['answers']['text']}} for ex in test_dataset]\n",
        "\n",
        "metric_result = metric.compute(predictions=formatted_predictions, references=references)\n",
        "\n",
        "print(\"Hasil evaluasi GRU:\")\n",
        "print(metric_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da868f4",
      "metadata": {},
      "source": [
        "## Bert\n",
        "Load ulang model Bert yang sudah di fine tuned kemudian buat trainernya kembali untuk prediksi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UjoviFc5dXXt",
      "metadata": {
        "id": "UjoviFc5dXXt"
      },
      "outputs": [],
      "source": [
        "bert_model = AutoModelForQuestionAnswering.from_pretrained(\"./model_bert\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "qtFMOEXJdZ4w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtFMOEXJdZ4w",
        "outputId": "2c7bb44c-3fb7-46f9-d385-682613b0dc38"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-41-ab6fa1c6fa9f>:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  bert_trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-qa-model\",\n",
        "    per_device_eval_batch_size=16,\n",
        ")\n",
        "\n",
        "bert_trainer = Trainer(\n",
        "    model=bert_model,\n",
        "    args=training_args,\n",
        "    tokenizer=bert_tokenizer,\n",
        "    data_collator=default_data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ce557d",
      "metadata": {},
      "source": [
        "#### Prediksi menggunakan model Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1b7acc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "43834412ab0a4907a1f3d74c0a082dba",
            "fc75153c212a43769e41ed1cb88faca7",
            "26c14516e2384b22ab066cd228670ee5",
            "02ce9fb8d5c64c0cb69307186927bcf8",
            "2470dc942e7c4519918c12c60a4cf755",
            "41b3389656924d4ca8def8e37b70d9ed",
            "17fae9ab1e5c48eeb1315e77ff2721c2",
            "90155e55ab714042b98c8c5ec04a75f2",
            "b45cdba2fd8b4fd092d4a4f96ee9a2ec",
            "7dc9596b11c54b48a2a2c11ba44a14b3",
            "375b226f6ece47538fd73ebd2d5ffde7"
          ]
        },
        "id": "de1b7acc",
        "outputId": "4a9763fc-84df-420d-c1bc-40a5147d512c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnathanchris435\u001b[0m (\u001b[33mnathanchris435-calvin-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250511_175008-6w7gu0pr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nathanchris435-calvin-institute-of-technology/huggingface/runs/6w7gu0pr' target=\"_blank\">./bert-qa-model</a></strong> to <a href='https://wandb.ai/nathanchris435-calvin-institute-of-technology/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nathanchris435-calvin-institute-of-technology/huggingface' target=\"_blank\">https://wandb.ai/nathanchris435-calvin-institute-of-technology/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nathanchris435-calvin-institute-of-technology/huggingface/runs/6w7gu0pr' target=\"_blank\">https://wandb.ai/nathanchris435-calvin-institute-of-technology/huggingface/runs/6w7gu0pr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43834412ab0a4907a1f3d74c0a082dba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hasil evaluasi Bert:\n",
            "{'exact_match': 40.9, 'f1': 53.39313913556089}\n"
          ]
        }
      ],
      "source": [
        "raw_predictions = bert_trainer.predict(tokenized_test_bert) # memprediksi dataset uji\n",
        "final_predictions = postprocess_qa_predictions(\n",
        "    test_dataset,  # versi asli\n",
        "    tokenized_test_bert,  # versi tokenisasi\n",
        "    raw_predictions.predictions # hasil logits\n",
        ")\n",
        "# menyusun hasil prediksi\n",
        "formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
        "\n",
        "# referensi jawaban asli\n",
        "references = [{\"id\": ex[\"id\"], \"answers\": {'answer_start': ex['answers']['answer_start'], 'text': ex['answers']['text']}} for ex in test_dataset]\n",
        "\n",
        "# evaluasi dengan SQuAD metrics\n",
        "metric_result = metric.compute(predictions=formatted_predictions, references=references)\n",
        "\n",
        "print(\"Hasil evaluasi Bert:\")\n",
        "print(metric_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1c2e908",
      "metadata": {},
      "source": [
        "## Roberta\n",
        "Load ulang model Roberta yang sudah di fine tuned kemudian buat trainernya kembali untuk prediksi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5R-TseYHeDvS",
      "metadata": {
        "id": "5R-TseYHeDvS"
      },
      "outputs": [],
      "source": [
        "roberta_model = AutoModelForQuestionAnswering.from_pretrained(\"./model_roberta\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "yfADdSgPeLMF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfADdSgPeLMF",
        "outputId": "9fe6ed56-4bf2-4261-b735-a942f25fea14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-44-24ec6feccbb0>:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  roberta_trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-qa-model\",\n",
        "    per_device_eval_batch_size=16,\n",
        ")\n",
        "\n",
        "roberta_trainer = Trainer(\n",
        "    model=roberta_model,\n",
        "    args=training_args,\n",
        "    tokenizer=roberta_tokenizer,\n",
        "    data_collator=default_data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea7200a",
      "metadata": {},
      "source": [
        "#### Prediksi menggunakan model Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d1dac1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "c3e29496c6144c289eb7cc59445a7bed",
            "5aab17fe6f3a4a6f8f41475048a9c6eb",
            "ca513f6da3604dc5ba5589b41d304106",
            "f89578e43a6f4fb5b4c0c47df656e1aa",
            "f6162ff8ce084167b48d1b77aaacde45",
            "45da632b5d1d4111aca5c3e27e26268e",
            "d8896dbf6cba4fbb9b909baee0f26d3a",
            "7fd87345f11748fcb26b85d4f542c657",
            "88b5053d2da343c9979cc671237897ab",
            "39ee0532c68a4a8aa41932320b1c5cb9",
            "c77fbe91a507464ebc2f344e01009d88"
          ]
        },
        "id": "5d1dac1f",
        "outputId": "26dac034-e068-47c7-b88a-67b235c6ac55"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3e29496c6144c289eb7cc59445a7bed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hasil evaluasi Roberta:\n",
            "{'exact_match': 48.2, 'f1': 70.56925233621385}\n"
          ]
        }
      ],
      "source": [
        "raw_predictions = roberta_trainer.predict(tokenized_test_roberta) # memprediksi dataset uji\n",
        "final_predictions = postprocess_qa_predictions(\n",
        "    test_dataset,  # versi asli\n",
        "    tokenized_test_roberta,  # versi tokenisasi\n",
        "    raw_predictions.predictions # hasil logits\n",
        ")\n",
        "\n",
        "# menyusun hasil prediksi\n",
        "formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
        "\n",
        "# referensi jawaban asli\n",
        "references = [{\"id\": ex[\"id\"], \"answers\": {'answer_start': ex['answers']['answer_start'], 'text': ex['answers']['text']}} for ex in test_dataset]\n",
        "\n",
        "# evaluasi dengan SQuAD metrics\n",
        "metric_result = metric.compute(predictions=formatted_predictions, references=references)\n",
        "\n",
        "print(\"Hasil evaluasi Roberta:\")\n",
        "print(metric_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "902d79ff",
      "metadata": {},
      "source": [
        "## Hasil Evaluasi Model\n",
        "\n",
        "| Nama Model  | F1 Score |   EM   |\n",
        "|-------------|----------|--------|\n",
        "| GRU         |   3.53   |  1.9   |\n",
        "| Bert        |  53.39   | 40.9   |\n",
        "| Roberta     |  70.57   | 48.2   |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gBVlwCyBLvb9",
      "metadata": {
        "id": "gBVlwCyBLvb9"
      },
      "source": [
        "# Inference\n",
        "Mencoba menggunakan model yang sudah dilatih untuk memprediksi output dari input baru"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24f74517",
      "metadata": {},
      "source": [
        "## Pertanyaan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ShcSisB8KrqK",
      "metadata": {
        "id": "ShcSisB8KrqK"
      },
      "outputs": [],
      "source": [
        "# Example\n",
        "question = \"Has patient ever been prescribed lopressor\"\n",
        "context = \"Mr. Quigg is a 42-year-old man with history of diabetes, end-stage renal disease on hemodialysis, left Charcot foot complicated by recurrent cellulitis who presented with left lower leg swelling, erythema, and pain. On admission, his temperature was 100.8, heart rate was 111, and blood pressure was 140/70. His left lower extremity had 1+ pitting edema with erythema on the anterior shin and foot. He was uptitrated to 5mg and also lopressor, started on Lyrica and oxycodone for breakthrough pain, and received Fentanyl PCA. His home medications included Colace 100 mg b.i.d., folate 1 mg p.o. daily, gemfibrozil 600 mg b.i.d., Lantus 30 mg subcu q.p.m., Lipitor 80 mg nightly, Nephrocaps, Neurontin 300 mg daily, PhosLo 2001 mg t.i.d., Protonix 40 mg daily, Renagel 3200 mg t.i.d., Requip 2 mg p.o. b.i.d., and Coumadin. His Lipitor was decreased to 20mg due to rhabdomylosis risk, and he was also started on low dose b-blocker to reduce perioperative MI risk prior to his surgery. His Vancomycin was continued given his history of MRSA cellulitis, with a goal of a level less than 20, and he was bridged with heparin with a goal PTT of 60-80. He was restarted on his Lantus and Aspart doses with meals, and his Coumadin was held prior to surgery and decreased to 20mg with a repeat lipid panel in 4-6 weeks. He required antibiotics which were discontinued at this time and he was discharged with dry sterile dressing changes to his residual limb daily, PTT goal 60-80, INR goal 2-3 until stable off of levofloxacin, monitoring of FS and adjustment of DM regimen, monitoring pain scale and decreasing pain medications as pain improves, hemodialysis M/W/F, and follow up with Dr. Carpino voice message left on his medical assistant's voice mail and Dr. Lynes 6/10/06 at 9:30am. Psychiatry service was consulted who recommended low dose Ativan prior to him going for dialysis. He was initially placed on a ketamine drip and given IV Levofloxacin and IV Flagyl to cover gram negatives and anaerobes respectively, and started on oxycontin 80mg tid with oxycodone for breakthrough pain and Lyrica for neuropathic pain. He was comfortable prior to discharge on this current regimen.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb888abe",
      "metadata": {},
      "source": [
        "## Expected Output: \n",
        "``` He was uptitrated to 5mg and also lopressor,```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "232f95fb",
      "metadata": {},
      "source": [
        "### GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17e28167",
      "metadata": {},
      "source": [
        "##### Model GRU membutuhkan metode tersendiri untuk prediksi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee105c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_gru_answer(model, question, context, tokenizer, max_length=384):\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Tokenisasi input\n",
        "    inputs = tokenizer(question, context,\n",
        "                       return_offsets_mapping=True,\n",
        "                       padding=\"max_length\",\n",
        "                       truncation=True,\n",
        "                       max_length=max_length,\n",
        "                       return_tensors=\"pt\")\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"].to(device)\n",
        "    offsets = inputs[\"offset_mapping\"][0]  # (seq_len, 2)\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        start_logits, end_logits = model(input_ids)\n",
        "\n",
        "    # Hapus kemungkinan dia mengambil index ke 0 (token CLS --> jawaban kosong)\n",
        "    start_logits = start_logits[:, 1:]\n",
        "    end_logits = end_logits[:, 1:]\n",
        "    offsets = offsets[1:]\n",
        "\n",
        "    # Ambil posisi tertinggi (logit paling besar)\n",
        "    start_index = torch.argmax(start_logits, dim=1).item()\n",
        "    end_index = torch.argmax(end_logits, dim=1).item()\n",
        "\n",
        "    # Koreksi jika end sebelum start\n",
        "    if end_index < start_index:\n",
        "        end_index = start_index\n",
        "\n",
        "    # Ambil teks asli dari context\n",
        "    tokens = input_ids[0][start_index:end_index + 1]\n",
        "    answer = tokenizer.decode(tokens, skip_special_tokens=True)\n",
        "\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf553227",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jawaban: . his vancomycin was continued given his history of mrsa cellulitis\n"
          ]
        }
      ],
      "source": [
        "result = predict_gru_answer(gru_model, question, context, bert_tokenizer)\n",
        "print(\"Jawaban:\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l5y9GpESMCnS",
      "metadata": {
        "id": "l5y9GpESMCnS"
      },
      "source": [
        "### Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "GuL3IutCLy99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuL3IutCLy99",
        "outputId": "6670b834-c8f2-4ea4-d05c-22db3f7617ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Load fine-tuned model\n",
        "bert_model = AutoModelForQuestionAnswering.from_pretrained(\"./model_bert\")\n",
        "\n",
        "# Create QA pipeline\n",
        "qa_bert_pipeline = pipeline(\"question-answering\", model=bert_model, tokenizer=bert_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "H91YYMzxL0B7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H91YYMzxL0B7",
        "outputId": "447a5522-b930-4c23-a354-a2013830576d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jawaban: started on Lyrica\n"
          ]
        }
      ],
      "source": [
        "result = qa_bert_pipeline(question=question, context=context)\n",
        "print(\"Jawaban:\", result['answer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T2t2KkOzMFKb",
      "metadata": {
        "id": "T2t2KkOzMFKb"
      },
      "source": [
        "### Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "QEgseGkQL-rr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEgseGkQL-rr",
        "outputId": "0b09ab85-71f3-42cf-aec6-1551737e271d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Load fine-tuned model\n",
        "roberta_model = AutoModelForQuestionAnswering.from_pretrained(\"./model_roberta\")\n",
        "\n",
        "# Create QA pipeline\n",
        "qa_roberta_pipeline = pipeline(\"question-answering\", model=roberta_model, tokenizer=roberta_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "k-9tMAtZL_dQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-9tMAtZL_dQ",
        "outputId": "21baf953-3860-4811-865b-1286bdfe209f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jawaban: He was uptitrated to 5mg and also lopressor,\n"
          ]
        }
      ],
      "source": [
        "result = qa_roberta_pipeline(question=question, context=context)\n",
        "print(\"Jawaban:\", result['answer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d227cbde",
      "metadata": {},
      "source": [
        "# Kesimpulan\n",
        "Dari ketiga model yang ada (GRU, BERT, dan RoBERTa), RoBERTa menjadi model yang menunjukkan performa terbaik untuk masalah Question Answering pada dataset ini. F1 score yang tinggi (70.57) menunjukkan bahwa model menghasilkan jawaban yang cukup akurat dengan aslinya. EM yang lebih tinggi (48.2) menunjukkan bahwa kemungkinan bahwa kemungkinan jawaban yang dihasilkan oleh RoBERTa lebih sering sama dengan jawaban aslinya. Sementara itu, BERT memiliki nilai f1 score dan EM di bawah RoBERTa. Hal ini menunjukkan bahwa RoBERTa lebih efektif dibandingkan BERT. Terakhir, GRU memiliki f1 score dan EM yang paling rendah di antara kedua model lainnya. Hal ini menunjukkan bahwa GRU kesulitan untuk memberikan jawaban yang tepat. Hal ini disebabkan karena GRU tidak dapat memberikan jawaban sebaik model-model Transformer"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02ce9fb8d5c64c0cb69307186927bcf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dc9596b11c54b48a2a2c11ba44a14b3",
            "placeholder": "​",
            "style": "IPY_MODEL_375b226f6ece47538fd73ebd2d5ffde7",
            "value": " 1000/1000 [00:05&lt;00:00, 213.59it/s]"
          }
        },
        "17fae9ab1e5c48eeb1315e77ff2721c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2470dc942e7c4519918c12c60a4cf755": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26c14516e2384b22ab066cd228670ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90155e55ab714042b98c8c5ec04a75f2",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b45cdba2fd8b4fd092d4a4f96ee9a2ec",
            "value": 1000
          }
        },
        "375b226f6ece47538fd73ebd2d5ffde7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39ee0532c68a4a8aa41932320b1c5cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41b3389656924d4ca8def8e37b70d9ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43834412ab0a4907a1f3d74c0a082dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc75153c212a43769e41ed1cb88faca7",
              "IPY_MODEL_26c14516e2384b22ab066cd228670ee5",
              "IPY_MODEL_02ce9fb8d5c64c0cb69307186927bcf8"
            ],
            "layout": "IPY_MODEL_2470dc942e7c4519918c12c60a4cf755"
          }
        },
        "45da632b5d1d4111aca5c3e27e26268e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aab17fe6f3a4a6f8f41475048a9c6eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45da632b5d1d4111aca5c3e27e26268e",
            "placeholder": "​",
            "style": "IPY_MODEL_d8896dbf6cba4fbb9b909baee0f26d3a",
            "value": "100%"
          }
        },
        "7dc9596b11c54b48a2a2c11ba44a14b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fd87345f11748fcb26b85d4f542c657": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88b5053d2da343c9979cc671237897ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90155e55ab714042b98c8c5ec04a75f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b45cdba2fd8b4fd092d4a4f96ee9a2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3e29496c6144c289eb7cc59445a7bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5aab17fe6f3a4a6f8f41475048a9c6eb",
              "IPY_MODEL_ca513f6da3604dc5ba5589b41d304106",
              "IPY_MODEL_f89578e43a6f4fb5b4c0c47df656e1aa"
            ],
            "layout": "IPY_MODEL_f6162ff8ce084167b48d1b77aaacde45"
          }
        },
        "c77fbe91a507464ebc2f344e01009d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca513f6da3604dc5ba5589b41d304106": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fd87345f11748fcb26b85d4f542c657",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88b5053d2da343c9979cc671237897ab",
            "value": 1000
          }
        },
        "d8896dbf6cba4fbb9b909baee0f26d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6162ff8ce084167b48d1b77aaacde45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f89578e43a6f4fb5b4c0c47df656e1aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39ee0532c68a4a8aa41932320b1c5cb9",
            "placeholder": "​",
            "style": "IPY_MODEL_c77fbe91a507464ebc2f344e01009d88",
            "value": " 1000/1000 [00:04&lt;00:00, 223.24it/s]"
          }
        },
        "fc75153c212a43769e41ed1cb88faca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41b3389656924d4ca8def8e37b70d9ed",
            "placeholder": "​",
            "style": "IPY_MODEL_17fae9ab1e5c48eeb1315e77ff2721c2",
            "value": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
